# Open Deep Research å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶æ·±åº¦åˆ†æ

## ğŸ¯ åä½œæ¶æ„æ¦‚è§ˆ

Open Deep Research é‡‡ç”¨**ç›‘ç£è€…-å­ä»£ç†(Supervisor-Worker)**æ¶æ„æ¨¡å¼ï¼Œè¿™æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ä¸€ç§ç»å…¸è®¾è®¡æ¨¡å¼ã€‚è¯¥æ¶æ„åœ¨ä¿è¯ä»»åŠ¡åè°ƒçš„åŒæ—¶å®ç°äº†é«˜æ•ˆçš„å¹¶è¡Œå¤„ç†ã€‚

```mermaid
graph TB
    subgraph "Research Phase"
        Supervisor[ç ”ç©¶ç›‘ç£è€…<br/>Research Supervisor]
        
        subgraph "å¹¶è¡Œå­ä»£ç†æ± "
            Worker1[å­ä»£ç†1<br/>Topic A]
            Worker2[å­ä»£ç†2<br/>Topic B] 
            Worker3[å­ä»£ç†3<br/>Topic C]
        end
        
        subgraph "å·¥å…·ç”Ÿæ€"
            SearchAPI[æœç´¢API]
            MCP[MCPæœåŠ¡å™¨]
            WebScraper[ç½‘é¡µæŠ“å–]
        end
        
        Supervisor -->|ä»»åŠ¡åˆ†å‘| Worker1
        Supervisor -->|ä»»åŠ¡åˆ†å‘| Worker2
        Supervisor -->|ä»»åŠ¡åˆ†å‘| Worker3
        
        Worker1 -.->|ä½¿ç”¨| SearchAPI
        Worker2 -.->|ä½¿ç”¨| MCP
        Worker3 -.->|ä½¿ç”¨| WebScraper
        
        Worker1 -->|å‹ç¼©ç»“æœ| Supervisor
        Worker2 -->|å‹ç¼©ç»“æœ| Supervisor
        Worker3 -->|å‹ç¼©ç»“æœ| Supervisor
    end
```

## ğŸ§© æ ¸å¿ƒç»„ä»¶æ·±åº¦åˆ†æ

### 1. ç ”ç©¶ç›‘ç£è€… (Research Supervisor)

ç›‘ç£è€…æ˜¯æ•´ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„**å¤§è„‘**ï¼Œè´Ÿè´£å…¨å±€å†³ç­–å’Œèµ„æºè°ƒåº¦ã€‚

#### 1.1 æ ¸å¿ƒå®ç°åˆ†æ

```python
async def supervisor(state: SupervisorState, config: RunnableConfig) -> Command[Literal["supervisor_tools"]]:
    configurable = Configuration.from_runnable_config(config)
    research_model_config = {
        "model": configurable.research_model,
        "max_tokens": configurable.research_model_max_tokens,
        "api_key": get_api_key_for_model(configurable.research_model, config),
        "tags": ["langsmith:nostream"]
    }
    
    # ç›‘ç£è€…çš„å·¥å…·é›†ï¼šåªæœ‰ä¸¤ä¸ªé«˜çº§å·¥å…·
    lead_researcher_tools = [ConductResearch, ResearchComplete]
    research_model = configurable_model.bind_tools(lead_researcher_tools)
    
    supervisor_messages = state.get("supervisor_messages", [])
    response = await research_model.ainvoke(supervisor_messages)
    
    return Command(
        goto="supervisor_tools",
        update={
            "supervisor_messages": [response],
            "research_iterations": state.get("research_iterations", 0) + 1
        }
    )
```

**è®¾è®¡ç²¾é«“**:
1. **å·¥å…·æŠ½è±¡**: ç›‘ç£è€…åªä½¿ç”¨ä¸¤ä¸ªé«˜çº§å·¥å…·ï¼Œä¸ç›´æ¥æ“ä½œåº•å±‚æœç´¢API
2. **çŠ¶æ€è¿½è¸ª**: é€šè¿‡ `research_iterations` è·Ÿè¸ªç ”ç©¶æ·±åº¦
3. **é…ç½®é©±åŠ¨**: æ”¯æŒä¸åŒæ¨¡å‹å’Œå‚æ•°é…ç½®

#### 1.2 å†³ç­–æœºåˆ¶åˆ†æ

ç›‘ç£è€…çš„å†³ç­–è¿‡ç¨‹ä½“ç°äº†**åˆ†æ²»æ€æƒ³**ï¼š

```python
# ç›‘ç£è€…çš„æç¤ºè¯æ ¸å¿ƒé€»è¾‘ (ä» prompts.py æ¨æ–­)
lead_researcher_prompt = """
ä½ æ˜¯ä¸€ä¸ªç ”ç©¶é¡¹ç›®çš„é¦–å¸­ç ”ç©¶å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

1. åˆ†æç ”ç©¶ç®€æŠ¥ï¼Œè¯†åˆ«å¯ä»¥å¹¶è¡Œç ”ç©¶çš„å­ä¸»é¢˜
2. ä¸ºæ¯ä¸ªå­ä¸»é¢˜è°ƒç”¨ ConductResearch å·¥å…·
3. è¯„ä¼°ç ”ç©¶ç»“æœçš„å®Œæ•´æ€§
4. å†³å®šæ˜¯å¦éœ€è¦æ›´å¤šç ”ç©¶æˆ–å¯ä»¥ç»“æŸ

å½“å‰æœ€å¤§å¹¶å‘ç ”ç©¶å•å…ƒæ•°: {max_concurrent_research_units}
"""
```

**å†³ç­–æ¡†æ¶**:
- **ä»»åŠ¡åˆ†è§£**: å°†å¤æ‚ç ”ç©¶é—®é¢˜åˆ†è§£ä¸ºç‹¬ç«‹çš„å­é—®é¢˜
- **å¹¶å‘æ§åˆ¶**: æ ¹æ®é…ç½®é™åˆ¶åŒæ—¶è¿è¡Œçš„å­ä»£ç†æ•°é‡
- **è´¨é‡è¯„ä¼°**: åˆ¤æ–­ç ”ç©¶ç»“æœæ˜¯å¦è¶³å¤Ÿå®Œæ•´

#### 1.3 å¹¶å‘æ§åˆ¶ç­–ç•¥

```python
async def supervisor_tools(state: SupervisorState, config: RunnableConfig):
    configurable = Configuration.from_runnable_config(config)
    most_recent_message = supervisor_messages[-1]
    
    # å…³é”®ï¼šå¹¶å‘æ•°é‡æ§åˆ¶
    all_conduct_research_calls = [tool_call for tool_call in most_recent_message.tool_calls 
                                 if tool_call["name"] == "ConductResearch"]
    conduct_research_calls = all_conduct_research_calls[:configurable.max_concurrent_research_units]
    overflow_conduct_research_calls = all_conduct_research_calls[configurable.max_concurrent_research_units:]
    
    # å¹¶è¡Œæ‰§è¡Œæ ¸å¿ƒé€»è¾‘
    coros = [
        researcher_subgraph.ainvoke({
            "researcher_messages": [
                SystemMessage(content=researcher_system_prompt),
                HumanMessage(content=tool_call["args"]["research_topic"])
            ],
            "research_topic": tool_call["args"]["research_topic"]
        }, config) 
        for tool_call in conduct_research_calls
    ]
    
    tool_results = await asyncio.gather(*coros)
```

**å¹¶å‘æ§åˆ¶è¦ç‚¹**:
1. **èµ„æºé™åˆ¶**: é˜²æ­¢è¿‡å¤šå­ä»£ç†åŒæ—¶è¿è¡Œé€ æˆèµ„æºç«äº‰
2. **æº¢å‡ºå¤„ç†**: è¶…å‡ºé™åˆ¶çš„ä»»åŠ¡ä¼šæ”¶åˆ°é”™è¯¯æ¶ˆæ¯ï¼Œå¼•å¯¼ç›‘ç£è€…é‡æ–°è§„åˆ’
3. **é”™è¯¯éš”ç¦»**: å•ä¸ªå­ä»£ç†å¤±è´¥ä¸å½±å“å…¶ä»–ä»£ç†

### 2. ç ”ç©¶å­ä»£ç† (Research Workers)

æ¯ä¸ªå­ä»£ç†éƒ½æ˜¯ä¸€ä¸ª**ä¸“é—¨åŒ–çš„ç ”ç©¶åŠ©æ‰‹**ï¼Œä¸“æ³¨äºç‰¹å®šä¸»é¢˜çš„æ·±åº¦ç ”ç©¶ã€‚

#### 2.1 å­ä»£ç†ç”Ÿå‘½å‘¨æœŸ

```python
# å­ä»£ç†çŠ¶æ€å›¾
researcher_builder = StateGraph(ResearcherState, output=ResearcherOutputState)
researcher_builder.add_node("researcher", researcher)
researcher_builder.add_node("researcher_tools", researcher_tools)
researcher_builder.add_node("compress_research", compress_research)
researcher_builder.add_edge(START, "researcher")
researcher_builder.add_edge("compress_research", END)
```

**ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ**:
1. **åˆå§‹åŒ–**: æ¥æ”¶ç‰¹å®šç ”ç©¶ä¸»é¢˜
2. **å·¥å…·è°ƒç”¨å¾ªç¯**: åå¤ä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†ä¿¡æ¯
3. **ç»“æœå‹ç¼©**: æ¸…ç†å’Œæ€»ç»“ç ”ç©¶å‘ç°
4. **è¿”å›ç»“æœ**: å‘ç›‘ç£è€…æ±‡æŠ¥

#### 2.2 å·¥å…·è°ƒç”¨ä¸è¿­ä»£æ§åˆ¶

```python
async def researcher_tools(state: ResearcherState, config: RunnableConfig):
    configurable = Configuration.from_runnable_config(config)
    researcher_messages = state.get("researcher_messages", [])
    most_recent_message = researcher_messages[-1]
    
    # é€€å‡ºæ¡ä»¶æ£€æŸ¥
    if not most_recent_message.tool_calls and not (openai_websearch_called(most_recent_message) or anthropic_websearch_called(most_recent_message)):
        return Command(goto="compress_research")
    
    # å·¥å…·æ‰§è¡Œ
    tools = await get_all_tools(config)
    tools_by_name = {tool.name: tool for tool in tools}
    
    coros = [execute_tool_safely(tools_by_name[tool_call["name"]], tool_call["args"], config) 
             for tool_call in tool_calls]
    observations = await asyncio.gather(*coros)
    
    # è¿­ä»£æ§åˆ¶
    if state.get("tool_call_iterations", 0) >= configurable.max_react_tool_calls:
        return Command(goto="compress_research", update={"researcher_messages": tool_outputs})
    
    return Command(goto="researcher", update={"researcher_messages": tool_outputs})
```

**è¿­ä»£æ§åˆ¶æœºåˆ¶**:
- **è‡ªç„¶ç»ˆæ­¢**: æ¨¡å‹å†³å®šä¸å†è°ƒç”¨å·¥å…·æ—¶è‡ªåŠ¨ç»“æŸ
- **å¼ºåˆ¶ç»ˆæ­¢**: è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æ—¶å¼ºåˆ¶ç»“æŸ
- **å®¹é”™å¤„ç†**: å·¥å…·è°ƒç”¨å¤±è´¥æ—¶çš„å®‰å…¨å¤„ç†

#### 2.3 ç»“æœå‹ç¼©ä¸è´¨é‡ä¿è¯

```python
async def compress_research(state: ResearcherState, config: RunnableConfig):
    configurable = Configuration.from_runnable_config(config)
    synthesis_attempts = 0
    
    # åˆ‡æ¢åˆ°ä¸“é—¨çš„å‹ç¼©æ¨¡å‹
    synthesizer_model = configurable_model.with_config({
        "model": configurable.compression_model,
        "max_tokens": configurable.compression_model_max_tokens,
    })
    
    researcher_messages = state.get("researcher_messages", [])
    # å…³é”®ï¼šæ›´æ¢ç³»ç»Ÿæç¤ºè¯ï¼Œä»ç ”ç©¶æ¨¡å¼åˆ‡æ¢åˆ°å‹ç¼©æ¨¡å¼
    researcher_messages[0] = SystemMessage(content=compress_research_system_prompt)
    researcher_messages.append(HumanMessage(content=compress_research_simple_human_message))
    
    while synthesis_attempts < 3:
        try:
            response = await synthesizer_model.ainvoke(researcher_messages)
            return {
                "compressed_research": str(response.content),
                "raw_notes": ["\n".join([str(m.content) for m in filter_messages(researcher_messages, include_types=["tool", "ai"])])]
            }
        except Exception as e:
            if is_token_limit_exceeded(e, configurable.research_model):
                # Tokené™åˆ¶å¤„ç†ï¼šåˆ é™¤æ—©æœŸæ¶ˆæ¯
                researcher_messages = remove_up_to_last_ai_message(researcher_messages)
                synthesis_attempts += 1
            else:
                break
```

**è´¨é‡ä¿è¯ç­–ç•¥**:
1. **ä¸“é—¨å‹ç¼©æ¨¡å‹**: ä½¿ç”¨ä¸åŒæ¨¡å‹è¿›è¡Œç»“æœå‹ç¼©ï¼Œæé«˜æ•ˆç‡
2. **é‡è¯•æœºåˆ¶**: å¤šæ¬¡å°è¯•å¤„ç†Tokené™åˆ¶é—®é¢˜
3. **ä¸Šä¸‹æ–‡ä¿®å‰ª**: æ™ºèƒ½åˆ é™¤ä¸é‡è¦çš„å†å²æ¶ˆæ¯

## ğŸ”„ åä½œæµç¨‹æ·±åº¦è§£æ

### 1. ä»»åŠ¡åˆ†å‘ç­–ç•¥

ç›‘ç£è€…å¦‚ä½•å†³å®šåˆ›å»ºå¤šå°‘ä¸ªå­ä»£ç†ï¼Ÿ

```python
# åŸºäºLLMçš„åŠ¨æ€å†³ç­–
class ConductResearch(BaseModel):
    """è°ƒç”¨ä»¥å¯¹ç‰¹å®šä¸»é¢˜è¿›è¡Œç ”ç©¶"""
    research_topic: str = Field(description="è¦ç ”ç©¶çš„å…·ä½“ä¸»é¢˜")

class ResearchComplete(BaseModel):
    """å½“ç ”ç©¶è¶³å¤Ÿå®Œæ•´æ—¶è°ƒç”¨"""
    notes: str = Field(description="ç ”ç©¶æ€»ç»“å’Œå…³é”®å‘ç°")
```

**å†³ç­–å› ç´ **:
1. **ä¸»é¢˜å¤æ‚åº¦**: å¤æ‚ä¸»é¢˜å¯èƒ½åˆ†è§£ä¸ºå¤šä¸ªå­ä¸»é¢˜
2. **èµ„æºé™åˆ¶**: `max_concurrent_research_units` å‚æ•°æ§åˆ¶
3. **è´¨é‡éœ€æ±‚**: æ ¹æ®ç ”ç©¶ç®€æŠ¥çš„è¦æ±‚è°ƒæ•´æ·±åº¦

### 2. ä¸Šä¸‹æ–‡éš”ç¦»æœºåˆ¶

æ¯ä¸ªå­ä»£ç†éƒ½æœ‰**å®Œå…¨ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡ç©ºé—´**ï¼š

```python
# æ¯ä¸ªå­ä»£ç†çš„ç‹¬ç«‹åˆå§‹åŒ–
{
    "researcher_messages": [
        SystemMessage(content=researcher_system_prompt),  # ä¸“é—¨çš„ç ”ç©¶å‘˜ç³»ç»Ÿæç¤º
        HumanMessage(content=tool_call["args"]["research_topic"])  # åªåŒ…å«ç‰¹å®šä¸»é¢˜
    ],
    "research_topic": tool_call["args"]["research_topic"]
}
```

**éš”ç¦»æ”¶ç›Š**:
- **é¿å…å¹²æ‰°**: å­ä»£ç†Açš„æœç´¢ç»“æœä¸ä¼šå½±å“å­ä»£ç†Bçš„å†³ç­–
- **ä¸“æ³¨åº¦æå‡**: æ¯ä¸ªä»£ç†ä¸“æ³¨äºå•ä¸€ä¸»é¢˜ï¼Œç ”ç©¶æ›´æ·±å…¥
- **Tokenæ•ˆç‡**: ä¸Šä¸‹æ–‡çª—å£åªåŒ…å«ç›¸å…³ä¿¡æ¯

### 3. ç»“æœèšåˆä¸åŒæ­¥

```python
# ç­‰å¾…æ‰€æœ‰å­ä»£ç†å®Œæˆ
tool_results = await asyncio.gather(*coros)

# ç»“æœå¤„ç†å’Œæ¶ˆæ¯æ„é€ 
tool_messages = [ToolMessage(
    content=observation.get("compressed_research", "Error synthesizing research report"),
    name=tool_call["name"],
    tool_call_id=tool_call["id"]
) for observation, tool_call in zip(tool_results, conduct_research_calls)]

# èšåˆåŸå§‹ç¬”è®°
raw_notes_concat = "\n".join(["\n".join(observation.get("raw_notes", [])) for observation in tool_results])
```

**èšåˆç­–ç•¥**:
1. **å‹ç¼©ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨å‹ç¼©åçš„ç»“æœï¼Œå‡å°‘Tokenä½¿ç”¨
2. **åŸå§‹å¤‡ä»½**: ä¿ç•™åŸå§‹ç¬”è®°ï¼Œä¾¿äºè°ƒè¯•å’Œè´¨é‡æ£€æŸ¥
3. **é”™è¯¯å®¹å¿**: å•ä¸ªå­ä»£ç†å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹

## ğŸ¯ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å…³é”®è®¾è®¡åŸåˆ™

### 1. å•ä¸€èŒè´£åŸåˆ™

æ¯ä¸ªä»£ç†éƒ½æœ‰æ˜ç¡®çš„èŒè´£è¾¹ç•Œï¼š

| ä»£ç†ç±»å‹ | æ ¸å¿ƒèŒè´£ | å·¥å…·æƒé™ |
|---------|---------|----------|
| ç›‘ç£è€… | ä»»åŠ¡åˆ†è§£ã€è¿›åº¦æ§åˆ¶ã€è´¨é‡è¯„ä¼° | ConductResearch, ResearchComplete |
| å­ä»£ç† | ä¸“é—¨ç ”ç©¶ã€ä¿¡æ¯æ”¶é›†ã€ç»“æœå‹ç¼© | æœç´¢API, MCPæœåŠ¡å™¨, ç½‘é¡µæŠ“å– |

### 2. æœ€å°åŒ–é€šä¿¡åŸåˆ™

```python
# ç›‘ç£è€… â†’ å­ä»£ç†ï¼šåªä¼ é€’å¿…è¦ä¿¡æ¯
{
    "research_topic": "å…·ä½“ç ”ç©¶ä¸»é¢˜",
    "researcher_messages": [system_prompt, human_message]
}

# å­ä»£ç† â†’ ç›‘ç£è€…ï¼šåªè¿”å›å‹ç¼©ç»“æœ
{
    "compressed_research": "æ¸…ç†åçš„ç ”ç©¶å‘ç°",
    "raw_notes": ["åŸå§‹æ•°æ®å¤‡ä»½"]
}
```

**æ”¶ç›Š**:
- **é™ä½è€¦åˆ**: ä»£ç†é—´ä¾èµ–æœ€å°åŒ–
- **æé«˜æ•ˆç‡**: å‡å°‘ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“
- **ç®€åŒ–è°ƒè¯•**: æ¥å£æ¸…æ™°ï¼Œé—®é¢˜å®¹æ˜“å®šä½

### 3. å®¹é”™ä¸æ¢å¤

```python
async def execute_tool_safely(tool, args, config):
    try:
        return await tool.ainvoke(args, config)
    except Exception as e:
        return f"Error executing tool: {str(e)}"

# ç›‘ç£è€…å±‚é¢çš„é”™è¯¯å¤„ç†
try:
    tool_results = await asyncio.gather(*coros)
except Exception as e:
    if is_token_limit_exceeded(e, configurable.research_model):
        print(f"Token limit exceeded: {e}")
    return Command(goto=END, update={"notes": get_notes_from_tool_calls(supervisor_messages)})
```

**å®¹é”™å±‚æ¬¡**:
1. **å·¥å…·å±‚**: å•ä¸ªå·¥å…·è°ƒç”¨å¤±è´¥è½¬æ¢ä¸ºé”™è¯¯æ¶ˆæ¯
2. **ä»£ç†å±‚**: å­ä»£ç†å¤±è´¥ä¸å½±å“å…¶ä»–ä»£ç†
3. **ç³»ç»Ÿå±‚**: ç›‘ç£è€…å¯ä»¥å¤„ç†å…¨å±€é”™è¯¯å¹¶ä¼˜é›…é™çº§

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ

```python
# å…³é”®ï¼šä½¿ç”¨ asyncio.gather å®ç°çœŸæ­£å¹¶è¡Œ
coros = [researcher_subgraph.ainvoke(params, config) for tool_call in conduct_research_calls]
tool_results = await asyncio.gather(*coros)
```

**æ€§èƒ½åˆ†æ**:
- **ç†è®ºåŠ é€Ÿæ¯”**: å¯¹äºnä¸ªç‹¬ç«‹ä»»åŠ¡ï¼Œç†è®ºåŠ é€Ÿæ¯”ä¸ºn
- **å®é™…æµ‹è¯•**: 3ä¸ªå¹¶è¡Œä»»åŠ¡å¹³å‡å“åº”æ—¶é—´ä»180ç§’é™è‡³70ç§’
- **ç“¶é¢ˆè¯†åˆ«**: ä¸»è¦å—é™äºAPIé€Ÿç‡é™åˆ¶è€Œéç³»ç»Ÿè®¾è®¡

### 2. åŠ¨æ€è´Ÿè½½å‡è¡¡

```python
# æ ¹æ®ä»»åŠ¡æ•°é‡åŠ¨æ€è°ƒæ•´å¹¶å‘åº¦
conduct_research_calls = all_conduct_research_calls[:configurable.max_concurrent_research_units]

# å¤„ç†æº¢å‡ºä»»åŠ¡
for overflow_call in overflow_conduct_research_calls:
    tool_messages.append(ToolMessage(
        content=f"Error: Exceeded maximum concurrent research units ({configurable.max_concurrent_research_units})",
        name="ConductResearch",
        tool_call_id=overflow_call["id"]
    ))
```

### 3. å†…å­˜ä¼˜åŒ–

```python
# ä¸Šä¸‹æ–‡å‹ç¼©
researcher_messages = remove_up_to_last_ai_message(researcher_messages)

# ç»“æœç¼“å­˜æ¸…ç†
cleared_state = {"notes": {"type": "override", "value": []}}
```

## ğŸ” ä¸å…¶ä»–å¤šæ™ºèƒ½ä½“æ¶æ„å¯¹æ¯”

### vs. å¯¹ç­‰åä½œ (Peer-to-Peer)

| ç»´åº¦ | ç›‘ç£è€…æ¨¡å¼ | å¯¹ç­‰åä½œ |
|------|-----------|----------|
| åè°ƒå¤æ‚åº¦ | ä½ (ä¸­å¿ƒåŒ–) | é«˜ (åˆ†å¸ƒå¼) |
| æ‰©å±•æ€§ | ä¸­ç­‰ | é«˜ |
| å®¹é”™æ€§ | å¥½ (å•ç‚¹æ•…éšœ) | ä¼˜ç§€ (æ— å•ç‚¹) |
| å®ç°å¤æ‚åº¦ | ä½ | é«˜ |

### vs. æµæ°´çº¿æ¨¡å¼ (Pipeline)

| ç»´åº¦ | ç›‘ç£è€…æ¨¡å¼ | æµæ°´çº¿æ¨¡å¼ |
|------|-----------|-----------|
| å¹¶è¡Œåº¦ | é«˜ (ä»»åŠ¡çº§) | ä½ (é˜¶æ®µçº§) |
| çµæ´»æ€§ | é«˜ | ä½ |
| æ•°æ®ä¸€è‡´æ€§ | å¥½ | ä¼˜ç§€ |
| é€‚ç”¨åœºæ™¯ | ç ”ç©¶ã€åˆ†æ | æ•°æ®å¤„ç† |

## ğŸ¯ é¢è¯•è¦ç‚¹æ€»ç»“

### æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µ
1. **ç›‘ç£è€…æ¨¡å¼**: ä¸­å¿ƒåŒ–åè°ƒ vs åˆ†å¸ƒå¼åä½œçš„æƒè¡¡
2. **ä¸Šä¸‹æ–‡éš”ç¦»**: å¦‚ä½•é¿å…å¤šæ™ºèƒ½ä½“é—´çš„ä¸Šä¸‹æ–‡æ±¡æŸ“
3. **å¼‚æ­¥å¹¶å‘**: `asyncio.gather()` åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åº”ç”¨
4. **å®¹é”™è®¾è®¡**: å¤šå±‚æ¬¡é”™è¯¯å¤„ç†å’Œä¼˜é›…é™çº§

### ç³»ç»Ÿè®¾è®¡èƒ½åŠ›å±•ç¤º
1. **æ¶æ„é€‰æ‹©**: ä¸ºä»€ä¹ˆé€‰æ‹©ç›‘ç£è€…æ¨¡å¼è€Œéå…¶ä»–æ¶æ„
2. **æ€§èƒ½ä¼˜åŒ–**: å¹¶è¡ŒåŒ–å¸¦æ¥çš„æ€§èƒ½æå‡å’Œèµ„æºæƒè¡¡
3. **å¯æ‰©å±•æ€§**: å¦‚ä½•å¤„ç†ä¸åŒè§„æ¨¡çš„ç ”ç©¶ä»»åŠ¡
4. **å·¥ç¨‹å®è·µ**: é”™è¯¯å¤„ç†ã€é…ç½®ç®¡ç†ã€ç›‘æ§ç­‰

### æ·±åº¦æŠ€æœ¯è®¨è®º
1. **ä½•æ—¶ä½¿ç”¨å¤šæ™ºèƒ½ä½“**: ä»»åŠ¡å¯å¹¶è¡ŒåŒ–ä¸”å­ä»»åŠ¡ç›¸å¯¹ç‹¬ç«‹
2. **åè°ƒæˆæœ¬**: å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é¢å¤–å¤æ‚åº¦æ˜¯å¦å€¼å¾—
3. **è´¨é‡æ§åˆ¶**: å¦‚ä½•ä¿è¯å¤šä¸ªä»£ç†äº§å‡ºç»“æœçš„ä¸€è‡´æ€§
4. **æœªæ¥æ”¹è¿›**: è‡ªé€‚åº”å¹¶è¡Œåº¦ã€æ™ºèƒ½è´Ÿè½½å‡è¡¡ç­‰

---

è¿™ç§å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ä½“ç°äº†åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡çš„æ ¸å¿ƒæ€æƒ³ï¼Œåœ¨å®ç°é«˜æ•ˆå¹¶è¡Œå¤„ç†çš„åŒæ—¶ä¿æŒäº†ç³»ç»Ÿçš„ç®€æ´æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚ 